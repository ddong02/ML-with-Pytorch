{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af5177e2-cd8b-4eb3-b175-ccde2809bc93",
      "metadata": {
        "tags": [],
        "id": "af5177e2-cd8b-4eb3-b175-ccde2809bc93"
      },
      "source": [
        "# 머신 러닝 교과서 - 파이토치편"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52744836",
      "metadata": {
        "id": "52744836"
      },
      "source": [
        "<table align=\"left\"><tr><td>\n",
        "<a href=\"https://colab.research.google.com/github/rickiepark/ml-with-pytorch/blob/main/ch13/ch13_part4_ignite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
        "</td></tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaed5d23-1f69-4ef6-96ac-328e0b464400",
      "metadata": {
        "id": "eaed5d23-1f69-4ef6-96ac-328e0b464400"
      },
      "source": [
        "## 패키지 버전 체크"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34c74f6a-16ea-49ae-ae40-695d79a9b0f3",
      "metadata": {
        "id": "34c74f6a-16ea-49ae-ae40-695d79a9b0f3"
      },
      "source": [
        "check_packages.py 스크립트에서 로드하기 위해 폴더를 추가합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0e488739-f8ab-4fb5-8790-5bb90b89ad25",
      "metadata": {
        "id": "0e488739-f8ab-4fb5-8790-5bb90b89ad25",
        "outputId": "f2302959-be39-4153-a2a5-43b84e6f834f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-11 02:37:30--  https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/python_environment_check.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1629 (1.6K) [text/plain]\n",
            "Saving to: ‘python_environment_check.py’\n",
            "\n",
            "\r          python_en   0%[                    ]       0  --.-KB/s               \rpython_environment_ 100%[===================>]   1.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-11 02:37:30 (30.5 MB/s) - ‘python_environment_check.py’ saved [1629/1629]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# 코랩의 경우 깃허브 저장소로부터 python_environment_check.py를 다운로드 합니다.\n",
        "if 'google.colab' in sys.modules:\n",
        "    !wget https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/python_environment_check.py\n",
        "else:\n",
        "    sys.path.insert(0, '..')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f550fbd0-78ec-4913-84e2-aef8c51bffed",
      "metadata": {
        "id": "f550fbd0-78ec-4913-84e2-aef8c51bffed"
      },
      "source": [
        "권장 패키지 버전을 확인하세요:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "50c6fe8e-e56c-40e3-ae21-07c57872e2ac",
      "metadata": {
        "id": "50c6fe8e-e56c-40e3-ae21-07c57872e2ac",
        "outputId": "7627f283-8c7f-4a8f-d977-b8ef44745c7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Your Python version is 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "[OK] numpy 1.23.5\n",
            "[OK] matplotlib 3.7.1\n",
            "[OK] sklearn 1.2.2\n"
          ]
        }
      ],
      "source": [
        "from python_environment_check import check_packages\n",
        "\n",
        "\n",
        "d = {\n",
        "    'numpy': '1.21.2',\n",
        "    'matplotlib': '3.4.3',\n",
        "    'sklearn': '1.0',\n",
        "}\n",
        "check_packages(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65f2a05",
      "metadata": {
        "tags": [],
        "id": "b65f2a05"
      },
      "source": [
        "# 13장 - 파이토치 구조 자세히 알아보기 (파트 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae32129-b9f5-4edf-bb04-6640c2da522b",
      "metadata": {
        "id": "1ae32129-b9f5-4edf-bb04-6640c2da522b"
      },
      "source": [
        "**이 섹션의 초안을 작성하고 도움을 주신 Victor Fomin에게 큰 감사와 공로를 돌립니다!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddec26f4",
      "metadata": {
        "id": "ddec26f4"
      },
      "source": [
        "## 파이토치 이그나이트 소개 (온라인 보너스 콘텐츠)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df6ab5c2-018c-4aa3-9a26-3e287bef8845",
      "metadata": {
        "id": "df6ab5c2-018c-4aa3-9a26-3e287bef8845"
      },
      "source": [
        "이 섹션에서는 파이토치에서 유연하고 투명하게 신경망을 훈련하고 평가하는 데 도움이 되는 파이토치 에코시스템의 라이브러리인 파이토치 이그나이트(PyTorch-Ignite)를 살펴보겠습니다.\n",
        "\n",
        "**파이토치 이그나이트를 사용한 프로젝트**\n",
        "\n",
        "\n",
        "파이토치 이그나이트를 사용하는 연구 논문, 블로그, 튜토리얼, 프로젝트가 많습니다. 그 중 유명한 프로젝트는 다음과 같습니다.\n",
        "- Medical Open Network for AI (MONAI) (https://monai.io)\n",
        "- Conversational AI with Transfer Learning (https://github.com/huggingface/transfer-learning-conv-ai)\n",
        "\n",
        "파이토치 이그나이트를 사용하는 더 많은 프로젝트는 다음 링크를 확인하세요: https://github.com/pytorch/ignite#projects-using-ignite"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10233840-52f3-4c62-86f6-10653c54072e",
      "metadata": {
        "id": "10233840-52f3-4c62-86f6-10653c54072e"
      },
      "source": [
        "---\n",
        "\n",
        "이전에 살펴본 것처럼, 파이토치 훈련 코드에는 일반적으로 두 개의 중첩된 for 루프가 포함됩니다. 하나는 에포크에 대해 반복하고 다른 하나는 데이터셋 배치에 대해 반복합니다. 또한 훈련 및 검증 세트에서 모델을 평가하여 훈련 중 성능을 추적합니다. 일반적으로 훈련 체크포인트를 생성하고(갑작스럽게 훈련이 실패할 경우 다시 시작하기 위해), 최상의 모델을 저장하고, 추적 시스템을 사용하여 손실, 예측 등을 시각화하는 등 입니다. 이러한 작업은 파이토치 이그나이트가 파이토치와 같은 유연성을 유지하면서 쉽게 처리할 수 있는 종류의 작업입니다. 이러한 의미에서 파이토치 이그나이트는 모범 사례를 촉진시키며 모델 훈련 프로세스를 간소화하는 것을 목표로 합니다.\n",
        "\n",
        "파이토치 이그나이트는 다음과 같은 기능을 제공합니다.\n",
        "- 매우 간단한 엔진 및 이벤트 시스템(훈련 루프 추상화)\n",
        "- 모델을 쉽게 평가할 수 있는 지표를 기본적으로 제공\n",
        "- 훈련 파이프라인을 구성하고, 모델을 저장하고, 매개변수와 측정 지표를 기록하는 내장 핸들러\n",
        "- 분산 훈련 지원\n",
        "\n",
        "파이토치 이그나이트 사용의 추가 이점은 다음과 같습니다.\n",
        "- 최대한의 제어와 단순성을 보장하면서 순수한 파이토치 보다 적은 코드량\n",
        "- 더 모듈화된 코드\n",
        "\n",
        "이 절에서는 MNIST 데이터셋에 대한 분류기를 다시 만들고 훈련해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df3d5ebf-f5ed-4b7b-9252-a9e38a03c22a",
      "metadata": {
        "id": "df3d5ebf-f5ed-4b7b-9252-a9e38a03c22a"
      },
      "source": [
        "---\n",
        "\n",
        "**파이토치 이그나이트 설치**\n",
        "\n",
        "이 노트북의 코드는 파이토치 이그나이트 버전 0.4.6을 기반으로 합니다. 파이토치 이그나이트는 pip 또는 conda를 통해 설치할 수 있습니다. 예를 들어, pip로 파이토치 이그나이트를 설치하는 명령은 다음과 같습니다:\n",
        "\n",
        "    pip install pytorch-ignite\n",
        "\n",
        "아래는 conda를 통해 파이토치 이그나이트를 설치하는 명령어입니다:\n",
        "\n",
        "    conda install ignite -c pytorch\n",
        "\n",
        "파이토치 이그나이트 설치에 대한 최신 정보는 공식 문서(https://pytorch.org/ignite/#installation)를 참조하시기 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-ignite"
      ],
      "metadata": {
        "id": "NnL7QsAYdRo2",
        "outputId": "b0945081-0923-49f6-f4ed-db521af8ed60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NnL7QsAYdRo2",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.12-py3-none-any.whl (266 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/266.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/266.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3,>=1.3->pytorch-ignite) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<3,>=1.3->pytorch-ignite) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7722db5f",
      "metadata": {
        "id": "7722db5f"
      },
      "source": [
        "### 파이토치 모델 준비하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b993ca1-d535-4431-af4e-7fd8d0f0a6c1",
      "metadata": {
        "id": "8b993ca1-d535-4431-af4e-7fd8d0f0a6c1"
      },
      "source": [
        "먼저, *프로젝트 2 - MNIST 손글씨 숫자 분류* 섹션의 1, 2, 3단계를 반복합니다. 모델, 훈련 및 검증 데이터셋, 옵티마이저, 손실 함수를 정의합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "220a5ea0",
      "metadata": {
        "id": "220a5ea0",
        "outputId": "851ab1de-7dfb-420e-b453-1c402b190f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 92337734.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31028610.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25378859.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7254580.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "image_path = './'\n",
        "torch.manual_seed(1)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "mnist_train_dataset = MNIST(\n",
        "    root=image_path,\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "mnist_val_dataset = MNIST(\n",
        "    root=image_path,\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(\n",
        "    mnist_train_dataset, batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    mnist_val_dataset, batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "def get_model(image_shape=(1, 28, 28), hidden_units=(32, 16)):\n",
        "    input_size = image_shape[0] * image_shape[1] * image_shape[2]\n",
        "    all_layers = [nn.Flatten()]\n",
        "    for hidden_unit in hidden_units:\n",
        "        layer = nn.Linear(input_size, hidden_unit)\n",
        "        all_layers.append(layer)\n",
        "        all_layers.append(nn.ReLU())\n",
        "        input_size = hidden_unit\n",
        "\n",
        "    all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
        "    all_layers.append(nn.Softmax(dim=1))\n",
        "    model = nn.Sequential(*all_layers)\n",
        "    return model\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = get_model().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7207c627-4559-4fe2-bccf-826394c7ead7",
      "metadata": {
        "id": "7207c627-4559-4fe2-bccf-826394c7ead7"
      },
      "source": [
        "여기서 보듯이 위의 코드는 이전에 소개한 파이토치 개념에만 의존하고 있습니다. 재사용 가능한 `get_model()` 함수를 정의하여 임의의 갯수의 은닉층을 가진 다층 퍼셉트론을 편리하게 생성할 수 있습니다. 은닉층 다음에는 ReLU 활성화가 이어집니다. 출력층 뒤에는 소프트맥스 함수가 이어집니다.\n",
        "\n",
        "MNIST 데이터셋에는 사전에 정의된 검증 세트 분할이 없습니다. 단순화를 위해 테스트 데이터 세트를 검증 세트로 사용했습니다. 하지만 모델 선택에 검증 세트를 사용하면 모델 성능에 대한 편향된 추정치를 제공하게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99dcabd0",
      "metadata": {
        "id": "99dcabd0"
      },
      "source": [
        "### 파이토치 이그나이트로 훈련과 평가 엔진 설정하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a2c594-a796-4621-b600-38c9388bc0e9",
      "metadata": {
        "id": "29a2c594-a796-4621-b600-38c9388bc0e9"
      },
      "source": [
        "가장 중요한 부분의 설정이 끝나면 파이토치 이그나이트가 다른 모든 반복적인 코드를 처리합니다. 다음으로, 지도 학습 모델을 간편하게 훈련하기 위해 모델, 옵티마이저, 손실 함수를 `ignite.engine.create_supervised_trainer()` 함수에 전달하여 트레이너 엔진을 정의해야 합니다(https://pytorch.org/ignite/generated/ignite.engine.create_supervised_trainer.html). 또한, 파이토치 이그나이트의 기본 지표와 모델을 `ignite.engine.create_supervised_evaluator()` 함수에 전달하여 평가 엔진을 생성합니다(https://pytorch.org/ignite/generated/ignite.engine.create_supervised_evaluator.html#create-supervised-evaluator):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c972bfa2",
      "metadata": {
        "id": "c972bfa2"
      },
      "outputs": [],
      "source": [
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "\n",
        "\n",
        "trainer = create_supervised_trainer(\n",
        "    model, optimizer, loss_fn, device=device\n",
        ")\n",
        "\n",
        "val_metrics = {\n",
        "    \"accuracy\": Accuracy(),\n",
        "    \"loss\": Loss(loss_fn)\n",
        "}\n",
        "\n",
        "evaluator = create_supervised_evaluator(\n",
        "    model, metrics=val_metrics, device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d21eb8-0825-4f7f-813b-0f0f5f3f6131",
      "metadata": {
        "id": "18d21eb8-0825-4f7f-813b-0f0f5f3f6131"
      },
      "source": [
        "`trainer`와 `evaluator` 객체는 모두 파이토치 이그나이트의 핵심 구성 요소 중 하나인 `Engine` 클래스(https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine)의 인스턴스입니다. 훈련 또는 검증 루프를 추상화한 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa17c608",
      "metadata": {
        "id": "aa17c608"
      },
      "source": [
        "### 로깅과 검증을 위한 이벤트 핸들러 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7cf3cdc-7a35-4a7a-8d36-6feaca029a85",
      "metadata": {
        "id": "f7cf3cdc-7a35-4a7a-8d36-6feaca029a85"
      },
      "source": [
        "모든 종류의 이벤트 핸들러를 추가하여 코드를 커스터마이징할 수 있습니다. `Engine`에 실행 중에 트리거되는 다양한 이벤트에 대한 핸들러를 추가할 수 있습니다. 이벤트가 트리거되면 추가된 핸들러(함수)가 실행됩니다. 로깅을 위해 모든 `log_interval` 반복이 끝날 때마다 실행될 함수를 추가합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0edafc78",
      "metadata": {
        "id": "0edafc78"
      },
      "outputs": [],
      "source": [
        "# 훈련 상태를 기록하기 전에 대기해야 하는 배치 수\n",
        "log_interval = 100\n",
        "\n",
        "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
        "def log_training_loss():\n",
        "    e = trainer.state.epoch\n",
        "    max_e = trainer.state.max_epochs\n",
        "    i = trainer.state.iteration\n",
        "    batch_loss = trainer.state.output\n",
        "    print(f\"Epoch[{e}/{max_e}], Iter[{i}] Loss: {batch_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52219744-e34e-4b97-885c-c19ec0e2cd4b",
      "metadata": {
        "id": "52219744-e34e-4b97-885c-c19ec0e2cd4b"
      },
      "source": [
        "또는 데코레이터 없이 `add_event_handler()` 호출을 통해 핸들러 함수를 트레이너에 첨부할 수 있습니다(https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine.add_event_handler).\n",
        "\n",
        "위에서 만든 훈련 상태 로깅을 위한 이벤트 핸들러를 만든 것과 유사하게, 각 에포크마다 검증 지표를 계산하기 위한 이벤트 핸들러를 만들 수 있습니다. 다음 코드를 통해 에포크가 완료되면 검증 세트 데이터 로더인 `val_loader`에서 `evaluator`를 실행할 것입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1944b444",
      "metadata": {
        "id": "1944b444"
      },
      "outputs": [],
      "source": [
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_results():\n",
        "    eval_state = evaluator.run(val_loader)\n",
        "    metrics = eval_state.metrics\n",
        "    e = trainer.state.epoch\n",
        "    max_e = trainer.state.max_epochs\n",
        "    acc = metrics['accuracy']\n",
        "    avg_loss = metrics['loss']\n",
        "    print(f\"검증 결과 - 에포크[{e}/{max_e}] 평균 정확도: {acc:.2f} 평균 손실: {avg_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11b8cdfa",
      "metadata": {
        "id": "11b8cdfa"
      },
      "source": [
        "### 훈련 체크포인트를 설정하고 최상의 모델 저장하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "773a23a4-6536-47d5-8710-05bb1407d2c5",
      "metadata": {
        "id": "773a23a4-6536-47d5-8710-05bb1407d2c5"
      },
      "source": [
        "훈련 과정에서 트레이너, 모델, 옵티마이저 및 기타 관련 객체를 저장하는 것이 일반적인 관행입니다. 이렇게 하면 갑작스럽게 훈련이 중단되는 경우 체크포인트에서 모델 훈련을 재개할 수 있습니다. 여기서는 기본 제공되는 파이토치 이그나이터 핸들러를 사용하여 각 에포크에 대한 훈련 체크포인트를 설정하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e451c03b",
      "metadata": {
        "id": "e451c03b",
        "outputId": "a470515d-fd3c-4110-998d-bef47bd5278c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x79c20035d300>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from ignite.handlers import Checkpoint, DiskSaver\n",
        "\n",
        "# 체크포인트에 다음을 저장합니다:\n",
        "to_save = {\"model\": model, \"optimizer\": optimizer, \"trainer\": trainer}\n",
        "\n",
        "# 로컬 디스크에 체크포인트를 저장합니다.\n",
        "output_path = \"./output\"\n",
        "save_handler = DiskSaver(dirname=output_path, require_empty=False)\n",
        "\n",
        "# 핸들러 준비:\n",
        "checkpoint_handler = Checkpoint(\n",
        "    to_save, save_handler, filename_prefix=\"training\")\n",
        "\n",
        "# 핸들러를 트레이너에 추가하기\n",
        "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73af287b-77b3-43d5-b47d-e9add713d991",
      "metadata": {
        "id": "73af287b-77b3-43d5-b47d-e9add713d991"
      },
      "source": [
        "위의 코드를 통해 나중에 모델을 저장하고 로드할 수 있는 `Checkpoint` 객체(https://pytorch.org/ignite/generated/ignite.handlers.checkpoint.Checkpoint.html#ignite.handlers.checkpoint.Checkpoint)를 만들었습니다.\n",
        "\n",
        "중단된 훈련 실행을 재개할 수 있도록 모델을 저장하는 것 외에도, 추론 단계에서 나중에 예측을 할 수 있도록 최적의 모델을 저장하는 것이 좋습니다. 그런 다음 12장의 훈련된 모델 저장 및 다시 로드하기 섹션에 설명된 대로 `torch.load`를 통해 저장된 모델을 로드할 수 있습니다.\n",
        "\n",
        "일반적으로 가장 좋은 모델은 검증 지표의 값에 의해 결정됩니다. 여기서는 동일한 핸들러인 `Checkpoint`를 사용하여 가장 높은 검증 정확도에 따라 최적의 모델을 저장하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e3c8def7",
      "metadata": {
        "id": "e3c8def7",
        "outputId": "7e3ff3da-d52c-4e59-9ccb-b10b88b0d8e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x79c15ad7be80>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 검증 정확도를 기준으로 최상의 모델을 저장합니다.\n",
        "best_model_handler = Checkpoint(\n",
        "    {\"model\": model},\n",
        "    save_handler,\n",
        "    filename_prefix=\"best\",\n",
        "    n_saved=1,\n",
        "    score_name=\"accuracy\",\n",
        "    score_function=Checkpoint.get_default_score_fn(\"accuracy\"),\n",
        ")\n",
        "\n",
        "evaluator.add_event_handler(Events.COMPLETED, best_model_handler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7092b069",
      "metadata": {
        "id": "7092b069"
      },
      "source": [
        "### 실험 추적 시스템으로 텐서보드 설정하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bdcedf6-b4ed-4172-843e-676ca8b65d1e",
      "metadata": {
        "id": "0bdcedf6-b4ed-4172-843e-676ca8b65d1e"
      },
      "source": [
        "다양한 구성으로 훈련을 실행할 때, 실험 추적 시스템(예: 텐서보드)을 사용하여 매개변수와 측정 지표를 기록하고 실험을 비교하는 것이 일반적인 관행입니다. 여기서는 `TensorboardLogger`(https://pytorch.org/ignite/generated/ignite.contrib.handlers.tensorboard_logger.html#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger)를 사용하여 트레이너의 손실 및 검증 지표를 기록하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9dc0368b",
      "metadata": {
        "id": "9dc0368b",
        "outputId": "c93464e8-c1fc-40f9-8c53-f00bd876c63c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x79c0f8a0d600>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine\n",
        "\n",
        "\n",
        "tb_logger = TensorboardLogger(log_dir=output_path)\n",
        "\n",
        "# 100번 반복마다 트레이너의 손실을 출력하는 핸들러\n",
        "tb_logger.attach_output_handler(\n",
        "    trainer,\n",
        "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
        "    tag=\"training\",\n",
        "    output_transform=lambda loss: {\"batch_loss\": loss},\n",
        ")\n",
        "\n",
        "# 에포크가 끝날 때마다 evaluator의 지표를 출력하는 핸들러\n",
        "tb_logger.attach_output_handler(\n",
        "    evaluator,\n",
        "    event_name=Events.EPOCH_COMPLETED,\n",
        "    tag=\"validation\",\n",
        "    metric_names=\"all\",\n",
        "    global_step_transform=global_step_from_engine(trainer),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad26fb6b",
      "metadata": {
        "id": "ad26fb6b"
      },
      "source": [
        "### 파이토치 이그나이트 모델 훈련 코드 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4216f020-b381-4880-8a00-dcb01a66524f",
      "metadata": {
        "id": "4216f020-b381-4880-8a00-dcb01a66524f"
      },
      "source": [
        "이제 트레이너가 설정되어 실행할 준비가 되었습니다. `run()` 메서드를 통해 5개의 에포크에 대해 모델을 훈련해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7f4d38cf",
      "metadata": {
        "id": "7f4d38cf",
        "outputId": "8be03311-08ef-4426-b6f4-6ae6d3eb3d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1/5], Iter[100] Loss: 1.82\n",
            "Epoch[1/5], Iter[200] Loss: 1.63\n",
            "Epoch[1/5], Iter[300] Loss: 1.65\n",
            "Epoch[1/5], Iter[400] Loss: 1.62\n",
            "Epoch[1/5], Iter[500] Loss: 1.56\n",
            "Epoch[1/5], Iter[600] Loss: 1.62\n",
            "Epoch[1/5], Iter[700] Loss: 1.57\n",
            "Epoch[1/5], Iter[800] Loss: 1.53\n",
            "Epoch[1/5], Iter[900] Loss: 1.52\n",
            "검증 결과 - 에포크[1/5] 평균 정확도: 0.91 평균 손실: 1.56\n",
            "Epoch[2/5], Iter[1000] Loss: 1.54\n",
            "Epoch[2/5], Iter[1100] Loss: 1.55\n",
            "Epoch[2/5], Iter[1200] Loss: 1.58\n",
            "Epoch[2/5], Iter[1300] Loss: 1.53\n",
            "Epoch[2/5], Iter[1400] Loss: 1.56\n",
            "Epoch[2/5], Iter[1500] Loss: 1.55\n",
            "Epoch[2/5], Iter[1600] Loss: 1.52\n",
            "Epoch[2/5], Iter[1700] Loss: 1.55\n",
            "Epoch[2/5], Iter[1800] Loss: 1.55\n",
            "검증 결과 - 에포크[2/5] 평균 정확도: 0.93 평균 손실: 1.54\n",
            "Epoch[3/5], Iter[1900] Loss: 1.50\n",
            "Epoch[3/5], Iter[2000] Loss: 1.52\n",
            "Epoch[3/5], Iter[2100] Loss: 1.53\n",
            "Epoch[3/5], Iter[2200] Loss: 1.56\n",
            "Epoch[3/5], Iter[2300] Loss: 1.53\n",
            "Epoch[3/5], Iter[2400] Loss: 1.54\n",
            "Epoch[3/5], Iter[2500] Loss: 1.54\n",
            "Epoch[3/5], Iter[2600] Loss: 1.60\n",
            "Epoch[3/5], Iter[2700] Loss: 1.58\n",
            "Epoch[3/5], Iter[2800] Loss: 1.55\n",
            "검증 결과 - 에포크[3/5] 평균 정확도: 0.93 평균 손실: 1.53\n",
            "Epoch[4/5], Iter[2900] Loss: 1.54\n",
            "Epoch[4/5], Iter[3000] Loss: 1.58\n",
            "Epoch[4/5], Iter[3100] Loss: 1.52\n",
            "Epoch[4/5], Iter[3200] Loss: 1.55\n",
            "Epoch[4/5], Iter[3300] Loss: 1.55\n",
            "Epoch[4/5], Iter[3400] Loss: 1.49\n",
            "Epoch[4/5], Iter[3500] Loss: 1.51\n",
            "Epoch[4/5], Iter[3600] Loss: 1.54\n",
            "Epoch[4/5], Iter[3700] Loss: 1.55\n",
            "검증 결과 - 에포크[4/5] 평균 정확도: 0.94 평균 손실: 1.53\n",
            "Epoch[5/5], Iter[3800] Loss: 1.50\n",
            "Epoch[5/5], Iter[3900] Loss: 1.53\n",
            "Epoch[5/5], Iter[4000] Loss: 1.51\n",
            "Epoch[5/5], Iter[4100] Loss: 1.54\n",
            "Epoch[5/5], Iter[4200] Loss: 1.53\n",
            "Epoch[5/5], Iter[4300] Loss: 1.53\n",
            "Epoch[5/5], Iter[4400] Loss: 1.51\n",
            "Epoch[5/5], Iter[4500] Loss: 1.51\n",
            "Epoch[5/5], Iter[4600] Loss: 1.51\n",
            "검증 결과 - 에포크[5/5] 평균 정확도: 0.94 평균 손실: 1.53\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 4690\n",
              "\tepoch: 5\n",
              "\tepoch_length: 938\n",
              "\tmax_epochs: 5\n",
              "\toutput: 1.4836150407791138\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "trainer.run(train_loader, max_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a0ba62e-6d9c-4dfd-a679-d67ca16edb23",
      "metadata": {
        "id": "9a0ba62e-6d9c-4dfd-a679-d67ca16edb23"
      },
      "source": [
        "`tensorboard --logdir ./output` 명령으로 텐서보드를 실행하여 브라우저에서 대시보드를 볼 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6dd9e080-f294-4314-ac8d-e023d4274d97",
      "metadata": {
        "id": "6dd9e080-f294-4314-ac8d-e023d4274d97",
        "outputId": "d0c967c1-4e79-413d-9d7f-079690b45576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch13/figures/ignite-01.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch13/figures/ignite-01.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a89d55-d4a9-4086-b285-0d346641b240",
      "metadata": {
        "id": "f0a89d55-d4a9-4086-b285-0d346641b240"
      },
      "source": [
        "---\n",
        "\n",
        "**파이토치 이그나이트 더 자세히 알아 보기**\n",
        "\n",
        "파이토치 이그나이트에 대해 자세히 알아보려면 공식 웹사이트(https://pytorch-ignite.ai)에서 튜토리얼과 사용 방법 가이드를 확인하세요.\n",
        "\n",
        "무엇보다도 이 웹사이트에는 편리한 파이토치 이그나이트 코드 생성기 애플리케이션(https://code-generator.pytorch-ignite.ai/)도 포함되어 있어 모든 것을 처음부터 다시 작성하지 않고도 작업을 시작할 수 있습니다.\n",
        "\n",
        "파이토치 이그나이트의 코드는 깃허브(https://github.com/pytorch/ignite)에 공개되어 있습니다. 이 프로젝트는 커뮤니티의 노력으로 이루어지며, 배경과 기술에 관계없이 누구나 기여하고 기여자 커뮤니티에 참여할 수 있습니다!\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}